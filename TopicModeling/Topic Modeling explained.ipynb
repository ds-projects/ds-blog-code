{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some days back, we implemented topic modeling on company reviews from Indeed using LDA algorithm. \n",
    "\n",
    "Today, we will try to understand how exactly LDA works with an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is build a topic model around these documents using LDA. In this post, we will try to understand the underpinnings of LDA algorithm. \n",
    "\n",
    "Let's say we have the following 5 sentences (copied from __[KD nuggets](http://www.kdnuggets.com/2016/07/text-mining-101-topic-modeling.html)__)\n",
    "\n",
    "- Document 1: I had a peanut butter sandwich for breakfast.\n",
    "- Document 2: I like to eat almonds, peanuts and walnuts.\n",
    "- Document 3: My neighbor got a little dog yesterday.\n",
    "- Document 4: Cats and dogs are mortal enemies.\n",
    "- Document 5: You must not feed peanuts to your dog.\n",
    "\n",
    "I have represented this in a list called 'documents' as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = ['I had a peanut butter sandwich for breakfast', \n",
    "             'I like to eat almonds, peanuts and walnuts',\n",
    "             'My neighbor got a little dog yesterday', \n",
    "             'Cats and dogs are mortal enemies', \n",
    "             'You must not feed peanuts to your dog']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the post on __[step-by-step LDA](https://dsprojectsblog.wordpress.com/2017/08/21/step-by-step-guide-to-build-your-first-topic-model-using-lda/)__, we first need to preprocess our data. At the very minimum, we should tokenize and remove stop words from our documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i had a peanut butter sandwich for breakfast',\n",
       " 'i like to eat almonds, peanuts and walnuts',\n",
       " 'my neighbor got a little dog yesterday',\n",
       " 'cats and dogs are mortal enemies',\n",
       " 'you must not feed peanuts to your dog']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercase all documents\n",
    "lc_doc = [doc.lower() for doc in documents]\n",
    "\n",
    "lc_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'had', 'a', 'peanut', 'butter', 'sandwich', 'for', 'breakfast'],\n",
       " ['i', 'like', 'to', 'eat', 'almonds', 'peanuts', 'and', 'walnuts'],\n",
       " ['my', 'neighbor', 'got', 'a', 'little', 'dog', 'yesterday'],\n",
       " ['cats', 'and', 'dogs', 'are', 'mortal', 'enemies'],\n",
       " ['you', 'must', 'not', 'feed', 'peanuts', 'to', 'your', 'dog']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize documents\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "tokenized_docs = [tokenizer.tokenize(doc) for doc in lc_doc]\n",
    "tokenized_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['peanut', 'butter', 'sandwich', 'breakfast'],\n",
       " ['like', 'eat', 'almonds', 'peanuts', 'walnuts'],\n",
       " ['neighbor', 'got', 'little', 'dog', 'yesterday'],\n",
       " ['cats', 'dogs', 'mortal', 'enemies'],\n",
       " ['must', 'feed', 'peanuts', 'dog']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove stop words\n",
    "nltk_stop_wds = stopwords.words('english')\n",
    "get_stop_wds = get_stop_words('en')\n",
    "all_stop_words = list(set(nltk_stop_wds + get_stop_wds))\n",
    "all_stop_words += ['.', '...', ',', '(', ')', ':', '`', '``', ';']\n",
    "all_stop_words += [\"'s\", \"n't\"]\n",
    "\n",
    "doc_wo_stopwords = [[token for token in doc if token not in all_stop_words] for doc in tokenized_docs]\n",
    "doc_wo_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have preprocessed list of documents, we can try to understand how topic modeling is performed based on this example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step1: We choose the number of topics beforehand**\n",
    "\n",
    "If you already have the domain knowledge, you may know the number of possible topics beforehand. \n",
    "\n",
    "Other ways to choose the optimal value can be based on trial and error or previous estimates\n",
    "\n",
    "By glancing over our example, we can say that we have roughly two topics: food and pets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step2: Randomly assign topic to every word in each document**\n",
    "\n",
    "Let's say following was the result of the initial random assignment of topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document 1</th>\n",
       "      <th>Randomly assigned topic</th>\n",
       "      <th>Document 2</th>\n",
       "      <th>Randomly assigned topic.1</th>\n",
       "      <th>Document 3</th>\n",
       "      <th>Randomly assigned topic.2</th>\n",
       "      <th>Document 4</th>\n",
       "      <th>Randomly assigned topic.3</th>\n",
       "      <th>Document 5</th>\n",
       "      <th>Randomly assigned topic.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>peanut</td>\n",
       "      <td>pets</td>\n",
       "      <td>like</td>\n",
       "      <td>food</td>\n",
       "      <td>neighbor</td>\n",
       "      <td>food</td>\n",
       "      <td>cats</td>\n",
       "      <td>pets</td>\n",
       "      <td>must</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>butter</td>\n",
       "      <td>food</td>\n",
       "      <td>eat</td>\n",
       "      <td>food</td>\n",
       "      <td>got</td>\n",
       "      <td>food</td>\n",
       "      <td>dogs</td>\n",
       "      <td>food</td>\n",
       "      <td>feed</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sandwich</td>\n",
       "      <td>food</td>\n",
       "      <td>almonds</td>\n",
       "      <td>food</td>\n",
       "      <td>little</td>\n",
       "      <td>pets</td>\n",
       "      <td>mortal</td>\n",
       "      <td>pets</td>\n",
       "      <td>peanuts</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>breakfast</td>\n",
       "      <td>pets</td>\n",
       "      <td>peanuts</td>\n",
       "      <td>food</td>\n",
       "      <td>dog</td>\n",
       "      <td>food</td>\n",
       "      <td>enemies</td>\n",
       "      <td>pets</td>\n",
       "      <td>dogs</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walnuts</td>\n",
       "      <td>food</td>\n",
       "      <td>yesterday</td>\n",
       "      <td>food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document 1 Randomly assigned topic Document 2 Randomly assigned topic.1  \\\n",
       "0     peanut                    pets       like                      food   \n",
       "1     butter                    food        eat                      food   \n",
       "2   sandwich                    food    almonds                      food   \n",
       "3  breakfast                    pets    peanuts                      food   \n",
       "4        NaN                     NaN    walnuts                      food   \n",
       "\n",
       "  Document 3 Randomly assigned topic.2 Document 4 Randomly assigned topic.3  \\\n",
       "0   neighbor                      food       cats                      pets   \n",
       "1        got                      food       dogs                      food   \n",
       "2     little                      pets     mortal                      pets   \n",
       "3        dog                      food    enemies                      pets   \n",
       "4  yesterday                      food        NaN                       NaN   \n",
       "\n",
       "  Document 5 Randomly assigned topic.4  \n",
       "0      must                       food  \n",
       "1       feed                      pets  \n",
       "2    peanuts                      food  \n",
       "3       dogs                      pets  \n",
       "4        NaN                       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step3:Iterate over every word in the document and update the topic**\n",
    "\n",
    "This is done in two steps:\n",
    "- By finding how relevant is word to the topic. Mathematically, this is computed as: p(word | topic), i.e, what is the probability that topic = 'food' given that our word is 'peanut'?\n",
    "\n",
    "This is computed by calculating proportion of assignments to topic t, over all documents d, that come from word w. \n",
    "\n",
    "So, in our example, 'peanut' is assigned to topic 'pets' in Document 1 and to 'food' in Document 2 and 5. \n",
    "\n",
    "So, p(topic = 'pets' | word = 'peanuts') = 1/3\n",
    "p(topic = 'food' | word = 'peanuts') = 2/3\n",
    "\n",
    "\n",
    "- Next, we find how relevant is the topic to the document. Mathematically, this is computed as p(topic | document), i.e, what is the probability that we can have Document 1 given that topic = 'food' / topic = 'pets'. \n",
    "\n",
    "This is computed by proportion of words in document d that are assigned to topic t. \n",
    "\n",
    "So, in our example, this probability will be computed as:\n",
    "\n",
    "p(topic = 'food' | Document1) = 2 / 4\n",
    "p(topic = 'pets' | Document 1) = 2 / 4\n",
    "\n",
    "- Then, we reassign word w a new topic t’, where we choose topic t’ with probability\n",
    "p(topic = new topic | document d) * p(word w | topic = new topic)\n",
    "\n",
    "So, in our example, the word 'peanut' in Document 1 is currently assigned to 'pets'. \n",
    "\n",
    "We will compute: \n",
    "\n",
    "p_food = p(topic = 'food' | Document1) * p(word = 'peanuts' | topic = 'food) = 2 / 4 * 2 / 3 = 1 / 3\n",
    "\n",
    "On the other hand, based on our current assignment for the word 'peanut', we have:\n",
    "\n",
    "p_pets = p(topic = 'food' | Document1) * p(word = 'peanuts' | topic = 'food) = 2 / 4 * 1 / 3 = 1 / 6\n",
    "\n",
    "So, as we can see, p_pets < p_food. Hence, we will update our topic assignment for 'peanuts' in Document 1 to 'food'\n",
    "\n",
    "Similary, we iterate over every word in the each document and keep updating the topics and cycling through the entire collection of documents multiple times. This iterative updating is the key feature of LDA that generates a final solution with coherent topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there you have it! This is how LDA works under the hood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
